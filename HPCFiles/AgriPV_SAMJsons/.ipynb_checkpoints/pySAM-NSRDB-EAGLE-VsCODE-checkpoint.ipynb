{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  NREL-rex for NSRDB from Eagle and PYSAM simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an example of calling NSRDB and pysam on https://github.com/NREL/pysam/blob/master/Examples/FetchResourceFileExample.py\n",
    "\n",
    "The difference is that example downloads the data into a .csv and saves the path file into the `solar_resource_file`.\n",
    "When having access to Eagle directly, all the data is loaded dynamically from the `.h5` file so saving .csvs slows process, so I want to pass the weather data directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T20:12:46.350659Z",
     "start_time": "2019-06-13T20:11:46.936643Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from rex import NSRDBX\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSRDBX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TMY data located on eagle about 900GB\n",
    "nsrdb_file = '/datasets/NSRDB/current/nsrdb_tmy-2021.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input\n",
    "region = 'Boulder'\n",
    "region_col = 'county'\n",
    "parameters = ['air_temperature', 'wind_speed', 'dhi', 'ghi', 'dni', 'surface_albedo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load time and geographical infos\n",
    "with NSRDBX(nsrdb_file, hsds=False) as f:\n",
    "    # Get time index\n",
    "    times = f.time_index\n",
    "    # Get geographical index for region of interest\n",
    "    gids = f.region_gids(region=region, region_col=region_col)   \n",
    "    # Get meta data\n",
    "    meta = f.meta[f.meta.index.isin(gids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load weather data\n",
    "data = []\n",
    "with NSRDBX(nsrdb_file, hsds=False) as f:\n",
    "        for p in parameters:\n",
    "            data.append(f.get_gid_df(p, gids)) #.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create multi-level dataframe\n",
    "columns = pd.MultiIndex.from_product([parameters, gids], names=[\"par\", \"gid\"])\n",
    "df_weather = pd.concat(data, axis=1)\n",
    "df_weather.columns = columns\n",
    "df_weather = df_weather.swaplevel(axis=1).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create results dataframe\n",
    "df_res = meta.loc[:, ['latitude', 'longitude']]\n",
    "df_res['distance'] = np.nan\n",
    "\n",
    "#loop through dataframe and perform computation \n",
    "#at the moment just saving the last location in the county of Boulder for use with pysam\n",
    "for gid, row in meta.iterrows():\n",
    "    meta_dict = row.to_dict()\n",
    "    df_weather_gid = df_weather.loc[:, gid]\n",
    "    tz_convert_val = meta_dict['timezone']\n",
    "    df_weather_gid = df_weather_gid.tz_convert(pytz.FixedOffset(tz_convert_val*60))\n",
    "    #df_weather_gid = df_weather_gid.tz_convert('Etc/GMT+7') # Localizing Data\n",
    "    # Maping to 2021 because the localizing sets the first values to the year before december...\n",
    "    df_weather_gid.index =  df_weather_gid.index.map(lambda t: t.replace(year=2021)) \n",
    "    # Then rearranging so they are at the end of hte dataframe, becuase I think SAM expect a 8760 starting at Jan 1 0 hours.\n",
    "    df_weather_gid = df_weather_gid.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "print(\"MetaData: \", meta_dict)\n",
    "print(\"\\nWeather DF keys\", df_weather_gid.keys())\n",
    "print(\"\\nDF length\", len(df_weather_gid))\n",
    "df_weather_gid.head(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_gid.tail(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySAM part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PySAM.Pvsamv1 as PV\n",
    "import PySAM.Grid as Grid\n",
    "import PySAM.Utilityrate5 as UtilityRate\n",
    "import PySAM.Cashloan as Cashloan\n",
    "import pathlib\n",
    "import json\n",
    "import os\n",
    "\n",
    "sif2 = 'AgriPV_SAMJsons'\n",
    "\n",
    "import PySAM\n",
    "PySAM.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [\"pvsamv1\", \"grid\", \"utilityrate5\", \"cashloan\"]\n",
    "\n",
    "pv2 = PV.new()  # also tried PVWattsSingleOwner\n",
    "grid2 = Grid.from_existing(pv2)\n",
    "ur2 = UtilityRate.from_existing(pv2)\n",
    "so2 = Cashloan.from_existing(grid2, 'FlatPlatePVCommercial')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, module in enumerate([pv2, grid2, ur2, so2]):\n",
    "    filetitle= 'AgriPV_SAM' + '_' + file_names[count] + \".json\"\n",
    "    with open(filetitle, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        for k, v in data.items():\n",
    "            if k == 'number_inputs':\n",
    "                continue\n",
    "            try:\n",
    "                module.value(k, v)\n",
    "            except AttributeError:\n",
    "                # there is an error is setting the value for ppa_escalation\n",
    "                print(module, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv2.SolarResource.solar_resource_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modifying it to a file that is local just for testing the results\n",
    "pv2.SolarResource.solar_resource_file = 'phoenix_az_33.450495_-111.983688_psmv3_60_tmy.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator.SolarResource.assign({'solar_resource_file': nsrdb_fp})\n",
    "#set_resource_data()\n",
    "grid2.SystemOutput.gen = [0] * 8760  # p_out   # let's set all the values to 0\n",
    "pv2.execute()\n",
    "grid2.execute()\n",
    "ur2.execute()\n",
    "so2.execute()\n",
    "\n",
    "results = pv2.Outputs.export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check \n",
    "dn = results['dn'][0:24]\n",
    "dhi = results['df'][0:24]\n",
    "alb = results['alb'][0:24]\n",
    "poa = results['poa_front'][0:24]\n",
    "power = results['subarray1_dc_gross'][0:24]\n",
    "pd.DataFrame(zip(dn, dhi, alb, poa, power), columns=['dn', 'dhi', 'alb', 'poa', 'power'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['air_temperature', 'alpha', 'aod', 'asymmetry', 'cld_opd_dcomp', 'cld_press_acha', 'cld_reff_dcomp', 'clearsky_dhi', 'clearsky_dni', 'clearsky_ghi', 'cloud_fill_flag', 'cloud_type', 'dew_point', 'dhi', 'dni', 'fill_flag', 'ghi', 'meta', 'ozone', 'relative_humidity', 'solar_zenith_angle', 'ssa', 'surface_albedo', 'surface_pressure', 'time_index', 'tmy_year', 'tmy_year_short', 'total_precipitable_water', 'wind_direction', 'wind_speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv2.SolarResource.solar_resource_file = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv2.SolarResource.replace('solar_resource_file') # Removes the file so it doesnt try to read it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check , This should give an exception:\n",
    "#pv2.SolarResource.solar_resource_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv2.SolarResource.assign({'solar_resource_data':{'dn':list(df_weather_gid.dni),\n",
    "                                                   'df':list(df_weather_gid.dhi),\n",
    "                                                   'tdry':list(df_weather_gid.air_temperature),\n",
    "                                                   'wspd':list(df_weather_gid.wind_speed),\n",
    "                                                   'lat':meta_dict['latitude'],\n",
    "                                                   'lon':meta_dict['longitude'],\n",
    "                                                   'tz':meta_dict['timezone'],\n",
    "                                                   'Elevation':meta_dict['elevation'],\n",
    "                                                   'Year':list(df_weather_gid.index.year),\n",
    "                                                   'Month':list(df_weather_gid.index.month),\n",
    "                                                   'Day':list(df_weather_gid.index.day),\n",
    "                                                   'Hour':list(df_weather_gid.index.hour),\n",
    "                                                   'Minute':list(df_weather_gid.index.minute),\n",
    "                                                   'alb':list(df_weather_gid.surface_albedo)}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure correct parameters are set on these \n",
    "pv2.SolarResource.irrad_mode = 0     # 0 for DNI and DHI input use\n",
    "pv2.SolarResource.use_wf_albedo = 1  # 1 for using weather file albedo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign albedo otherwise it fails even if use_wf_albedo=1, 'bug' reported\n",
    "pv2.SolarResource.albedo = list(df_weather_gid.surface_albedo) # \n",
    "pv2.SolarResource.albedo = [0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(pv2.SolarResource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2.SystemOutput.gen = [0] * 8760  # p_out   # let's set all the values to 0\n",
    "pv2.execute()\n",
    "grid2.execute()\n",
    "ur2.execute()\n",
    "so2.execute()\n",
    "\n",
    "results = pv2.Outputs.export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check \n",
    "dn = results['dn'][0:24]\n",
    "dhi = results['df'][0:24]\n",
    "alb = results['alb'][0:24]\n",
    "poa = results['poa_front'][0:24]\n",
    "power = results['subarray1_dc_gross'][0:24]\n",
    "pd.DataFrame(zip(dn, dhi, alb, poa, power), columns=['dn', 'dhi', 'alb', 'poa', 'power'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results['subarray1_dc_gross'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eventually will save and parse results from\n",
    "# results['subarray1_ground_rear_spatial']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jan23",
   "language": "python",
   "name": "jan23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
